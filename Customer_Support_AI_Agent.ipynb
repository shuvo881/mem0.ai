{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that your order hasn't arrived yet. I'd be happy to assist you with this. Can you please provide me with the order number or any other information that could help me find your order in our system?"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from mem0 import Memory\n",
    "\n",
    "# Set the OpenAI API key\n",
    "\n",
    "class CustomerSupportAIAgent:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the CustomerSupportAIAgent with memory configuration and OpenAI client.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            \"vector_store\": {\n",
    "                \"provider\": \"qdrant\",\n",
    "                \"config\": {\n",
    "                    \"host\": \"localhost\",\n",
    "                    \"port\": 6333,\n",
    "                }\n",
    "            },\n",
    "            'version':'v1.1'\n",
    "        }\n",
    "        self.memory = Memory.from_config(config)\n",
    "        self.client = OpenAI()\n",
    "        self.app_id = \"customer-support\"\n",
    "\n",
    "    def handle_query(self, query, user_id=None):\n",
    "        \"\"\"\n",
    "        Handle a customer query and store the relevant information in memory.\n",
    "\n",
    "        :param query: The customer query to handle.\n",
    "        :param user_id: Optional user ID to associate with the memory.\n",
    "        \"\"\"\n",
    "        # Start a streaming chat completion request to the AI\n",
    "        stream = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            stream=True,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a customer support AI agent.\"},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ]\n",
    "        )\n",
    "        # Store the query in memory\n",
    "        self.memory.add(query, user_id=user_id, metadata={\"app_id\": self.app_id})\n",
    "\n",
    "        # Print the response from the AI in real-time\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "    def get_memories(self, user_id=None):\n",
    "        \"\"\"\n",
    "        Retrieve all memories associated with the given customer ID.\n",
    "\n",
    "        :param user_id: Optional user ID to filter memories.\n",
    "        :return: List of memories.\n",
    "        \"\"\"\n",
    "        return self.memory.get_all(user_id=user_id)\n",
    "\n",
    "# Instantiate the CustomerSupportAIAgent\n",
    "support_agent = CustomerSupportAIAgent()\n",
    "\n",
    "# Define a customer ID\n",
    "customer_id = \"jane_doe\"\n",
    "\n",
    "# Handle a customer query\n",
    "support_agent.handle_query(\"I need help with my recent order. It hasn't arrived yet.\", user_id=customer_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I need a bit more context in order to assist you efficiently. Are you having an issue with your order or would you like to inquire about the status of your order with the number 678?"
     ]
    }
   ],
   "source": [
    "support_agent.handle_query(\"the order number 678.\", user_id=customer_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '4a383650-8283-4723-a21c-2b6d1bde5356', 'memory': \"Need help with recent order that hasn't arrived yet\", 'hash': 'b4adcc05e9ecfaeb9a274db97448dd47', 'metadata': {'app_id': 'customer-support'}, 'created_at': '2024-12-19T02:14:54.096058-08:00', 'updated_at': None, 'user_id': 'jane_doe'}\n",
      "{'id': 'b9aea8dd-a130-4652-985b-ce4f447a871f', 'memory': 'Order number is 678', 'hash': 'ca9fb46c98aa6f19b8b2ea922a7a9ac5', 'metadata': {'app_id': 'customer-support'}, 'created_at': '2024-12-19T02:17:33.856089-08:00', 'updated_at': '2024-12-19T02:21:22.527845-08:00', 'user_id': 'jane_doe'}\n"
     ]
    }
   ],
   "source": [
    "memories = support_agent.get_memories(user_id=customer_id)\n",
    "for m in memories['results']:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
